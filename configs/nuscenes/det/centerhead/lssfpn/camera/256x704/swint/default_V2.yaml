voxel_size: [0.075, 0.075, 0.2]
point_cloud_range: [-54, -54, -5, 54, 54, 3]
out_size_factor: 11.25 # 8 # if want to modify bev size, need to modify this value
voxel_shape: 1440   # int((point_cloud_range[3]-point_cloud_range[0])//voxel_size[0])
bev_size: 128 # 180 # voxel_shape//out_size_factor, consider after downsample
grid_size: # [[bev_size, bev_size, 1], [bev_size//2, bev_size//2, 1]]
  - [128, 128, 1]
  - [64, 64, 1] 
region_shape:
  - [6, 6, 1]
  - [6, 6, 1]
region_drop_info:
  - {0: { 'max_tokens': 36, 'drop_range': [0, 100000] }}
  - {0: { 'max_tokens': 36, 'drop_range': [0, 100000] }}

model:
  type: BEVFusionV2
  encoders:
    camera:
      backbone:
        type: SwinTransformer
        embed_dims: 96
        depths: [2, 2, 6, 2]
        num_heads: [3, 6, 12, 24]
        window_size: 7
        mlp_ratio: 4
        qkv_bias: true
        qk_scale: null
        drop_rate: 0.
        attn_drop_rate: 0.
        drop_path_rate: 0.2
        patch_norm: true
        out_indices: [1, 2, 3]
        with_cp: false
        convert_weights: true
        init_cfg:
          type: Pretrained
          checkpoint: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
      neck:
        type: GeneralizedLSSFPN
        in_channels: [192, 384, 768]
        out_channels: 256
        start_level: 0
        num_outs: 3
        norm_cfg:
          type: BN2d
          requires_grad: true
        act_cfg:
          type: ReLU
          inplace: true
        upsample_cfg:
          mode: bilinear
          align_corners: false      
      vtransform:
        type: LSSTransformV2
        in_channels: 256
        out_channels: 128 # 80
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        xbound: [-51.2, 51.2, 0.4]
        ybound: [-51.2, 51.2, 0.4]
        zbound: [-10.0, 10.0, 20.0]
        dbound: [1.0, 60.0, 0.5]
        downsample: 2
        ### the following parameters are used for grid2region and instance fusion for bev feats
        embed_dims: 256 # (be channel * 2)
        num_views: 6
        num_classes: 10 # 10 detection object classes
        bev_size: ${bev_size}
        region_shape: ${region_shape}
        grid_size: ${grid_size}
        region_drop_info: ${region_drop_info}
        instance_num: 200

  bevfeats_processor:
    backbone:
      type: SECONDV2
      in_channels: 128 # 80  # Input channels from vtransform output
      out_channels: [128, 256]
      layer_nums: [5, 5]
      layer_strides: [1, 2]
      norm_cfg:
        type: BN
        eps: !!float 1e-3
        momentum: 0.01
      conv_cfg:
        type: Conv2d
        bias: false

    neck:
      type: SECONDFPN
      in_channels: [128, 256]
      out_channels: [256, 256]
      upsample_strides: [1, 2]
      norm_cfg:
        type: BN
        eps: !!float 1e-3
        momentum: 0.01
      upsample_cfg:
        type: deconv
        bias: false
      use_conv_for_no_stride: true

  # decoder:
  #   backbone:
  #     type: SECONDV2
  #     in_channels: 128 # 80  # Input channels from vtransform output
  #     out_channels: [128, 256]
  #     layer_nums: [5, 5]
  #     layer_strides: [1, 2]
  #     norm_cfg:
  #       type: BN
  #       eps: !!float 1e-3
  #       momentum: 0.01
  #     conv_cfg:
  #       type: Conv2d
  #       bias: false

  #   neck:
  #     type: SECONDFPN
  #     in_channels: [128, 256]
  #     out_channels: [256, 256]
  #     upsample_strides: [1, 2]
  #     norm_cfg:
  #       type: BN
  #       eps: 1e-3
  #       momentum: 0.01
  #     upsample_cfg:
  #       type: deconv
  #       bias: false
  #     use_conv_for_no_stride: true

  decoder:
    backbone:
      type: GeneralizedResNetV2
      in_channels: 512 # (256*2) # 80
      blocks:
        - [2, 128, 2]
        - [2, 256, 2]
        - [2, 512, 1]
    neck:
      type: LSSFPN
      in_indices: [-1, 0]
      in_channels: [512, 128]
      out_channels: 256
      scale_factor: 2

optimizer:
  paramwise_cfg:
    custom_keys:
      absolute_pos_embed:
        decay_mult: 0
      relative_position_bias_table:
        decay_mult: 0
      encoders.camera.backbone:
        lr_mult: 0.1


lr_config:
  policy: cyclic
  target_ratio: 5.0
  cyclic_times: 1
  step_ratio_up: 0.4

momentum_config:
  policy: cyclic
  cyclic_times: 1
  step_ratio_up: 0.4

data:
  samples_per_gpu: 4
